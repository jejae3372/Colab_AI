{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPupzfUA4o8kCqgsD43e2Bj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5h8GuxLJlpm2","executionInfo":{"status":"ok","timestamp":1683256074757,"user_tz":-540,"elapsed":72682,"user":{"displayName":"qnqnqh 1234","userId":"03505967111581241624"}},"outputId":"77622c22-2523-48ac-e2d8-d8b8ee9e8ad7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_25\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_25 (Flatten)        (None, 784)               0         \n","                                                                 \n"," dense_50 (Dense)            (None, 100)               78500     \n","                                                                 \n"," dense_51 (Dense)            (None, 10)                1010      \n","                                                                 \n","=================================================================\n","Total params: 79,510\n","Trainable params: 79,510\n","Non-trainable params: 0\n","_________________________________________________________________\n","375/375 [==============================] - 1s 1ms/step\n","0.8778333333333334\n","Epoch 1/10\n","1500/1500 [==============================] - 5s 3ms/step - loss: 0.5971 - accuracy: 0.7896 - val_loss: 0.4439 - val_accuracy: 0.8394\n","Epoch 2/10\n","1500/1500 [==============================] - 5s 3ms/step - loss: 0.4404 - accuracy: 0.8416 - val_loss: 0.4084 - val_accuracy: 0.8512\n","Epoch 3/10\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.4037 - accuracy: 0.8513 - val_loss: 0.3729 - val_accuracy: 0.8612\n","Epoch 4/10\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.3837 - accuracy: 0.8596 - val_loss: 0.3624 - val_accuracy: 0.8652\n","Epoch 5/10\n","1500/1500 [==============================] - 5s 3ms/step - loss: 0.3661 - accuracy: 0.8677 - val_loss: 0.3417 - val_accuracy: 0.8728\n","Epoch 6/10\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.3552 - accuracy: 0.8683 - val_loss: 0.3437 - val_accuracy: 0.8740\n","Epoch 7/10\n","1500/1500 [==============================] - 4s 3ms/step - loss: 0.3456 - accuracy: 0.8748 - val_loss: 0.3502 - val_accuracy: 0.8732\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f24ffbc2dd0>"]},"metadata":{},"execution_count":11}],"source":["from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n","train_scaled = train_input / 255.0\n","train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size = 0.2, random_state = 42)\n","\n","def model_fn(a_layer = None):\n","  model = keras.Sequential()\n","  model.add(keras.layers.Flatten(input_shape=(28,28)))\n","  model.add(keras.layers.Dense(100, activation='relu'))\n","  if a_layer:\n","    model.add(a_layer)\n","  model.add(keras.layers.Dense(10, activation='softmax'))\n","  return model\n","\n","model = model_fn()\n","model.summary()\n","'''\n","model.compile(loss = 'sparse_categorical_crossentropy', metrics = 'accuracy')\n","history = model.fit(train_scaled, train_target, epochs = 20, verbose = 0)        #verbose = 0 -> 훈련과정 출력 X\n","\n","import matplotlib.pyplot as plt\n","plt.plot(history.history['loss'])\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.show()\n","\n","plt.plot(history.history['accuracy'])\n","plt.xlabel('epoch')\n","plt.ylabel('accuracy')\n","plt.show()\n","\n","adam = keras.optimizers.Adam(learning_rate = 0.1  )\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = 'accuracy')\n","history = model.fit(train_scaled, train_target, epochs = 20, verbose = 0,\n","                    validation_data =(val_scaled, val_target))\n","import matplotlib.pyplot as plt\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.legend(['train', 'val'])\n","plt.show()\n","'''\n","model = model_fn(keras.layers.Dropout(0.3))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = 'accuracy')\n","history = model.fit(train_scaled, train_target, epochs = 10, verbose = 0, validation_data = (val_scaled, val_target))\n","model.save_weights('model-weights.h5')      #모델의 파라미터 저장\n","model.save('model-whole.h5')                #모델 구조와 파라미터 저장\n","\n","model = model_fn(keras.layers.Dropout(0.3))\n","model.load_weights('model-weights.h5')\n","\n","import numpy as np\n","val_labels = np.argmax(model.predict(val_scaled), axis= -1)\n","print(np.mean(val_labels == val_target))\n","\n","model = model_fn(keras.layers.Dropout(0.3))\n","model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = 'accuracy')\n","checkpoint_cb = keras.callbacks.ModelCheckpoint('best-model.h5', save_best_only = True)           #ModelCheckpoint  save_best_only -> 가장 낮은 검증 손실 점수를 낸 모델 저장 (에포크 횟수)\n","early_stopping_cb = keras.callbacks.EarlyStopping(patience = 2, restore_best_weights = True)       #에포크를 끝까지 수행하지않고 patience 값 연속으로 검증 손실 점수 가 향상되지 않으면 그대로 중지\n","model.fit(train_scaled, train_target, epochs = 10, verbose = 1, validation_data = (val_scaled, val_target), callbacks = [checkpoint_cb, early_stopping_cb])\n","\n","\n"]}]}