{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZ3RTOZxUV1oBUSchihcPH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jejae3372/Colab_AI/blob/main/Pre_trained_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.3.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSTCEDIRdvlg",
        "outputId": "d2c3bc75-4fd0-46b5-a406-87d0649489d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.3.1\n",
            "  Downloading torchtext-0.3.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.3.1) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.3.1) (2.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.3.1) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.3.1) (1.23.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.3.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.3.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.3.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.3.1) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.3.1) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.3.1) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.3.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.3.1) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.3.1) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.3.1) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.3.1) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.3.1) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.3.1) (1.3.0)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.16.0\n",
            "    Uninstalling torchtext-0.16.0:\n",
            "      Successfully uninstalled torchtext-0.16.0\n",
            "Successfully installed torchtext-0.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UsoQj3f3biX1"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import sys\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext import data\n",
        "from torchtext import datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT = data.Field(batch_first = True,\n",
        "                  fix_length = 500,\n",
        "                  tokenize = str.split,\n",
        "                  pad_first = True,\n",
        "                  pad_token = '[PAD]',\n",
        "                  unk_token = '[UNK]')\n",
        "\n",
        "LABEL = data.LabelField(dtype = torch.float)\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(text_field = TEXT,\n",
        "                                             label_field = LABEL)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W73iA_s0d_yD",
        "outputId": "c0df2c24-b72d-411b-cad4-8ff8043dbcb7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:04<00:00, 18.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def PreProcessingText(input_sentence):\n",
        "  input_sentence = input_sentence.lower()\n",
        "  input_sentence = re.sub('<[^>]*>', repl= ' ', string = input_sentence)\n",
        "  input_sentence = re.sub('[!\"#$%&\\()*+,-./:;<=>?@[\\\\]^_`{|}~]', repl= ' ', string = input_sentence)\n",
        "  input_sentence = re.sub('\\s+', repl = ' ', string = input_sentence)\n",
        "  if input_sentence:\n",
        "    return input_sentence\n",
        "\n",
        "for example in train_data.examples:\n",
        "  vars(example)['text'] = PreProcessingText(' '.join(vars(example)['text'])).split()\n",
        "\n",
        "for example in test_data.examples:\n",
        "  vars(example)['text'] = PreProcessingText(' '.join(vars(example)['text'])).split()\n"
      ],
      "metadata": {
        "id": "6uxEiequeOnF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = {'emb_type': 'glove', 'emb_dim': 300}\n",
        "TEXT.build_vocab(train_data,\n",
        "                 min_freq = 2,\n",
        "                 max_size = None,\n",
        "                 vectors = f\"glove.6B.{model_config['emb_dim']}d\")\n",
        "LABEL.build_vocab(train_data)\n",
        "model_config['vocab_size'] = len(TEXT.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tM5GhSy8hlla",
        "outputId": "3711a537-2ac2-4e57-9bb5-de27152a7836"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:39, 5.40MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:37<00:00, 10572.92it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, vaild_data = train_data.split(random_state = random.seed(0), split_ratio = 0.8)"
      ],
      "metadata": {
        "id": "4wRXtCFjjq8H"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config['batch_size'] = 30\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, vaild_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, vaild_data, test_data),\n",
        "    batch_size = model_config['batch_size'],\n",
        "    device = device\n",
        ")"
      ],
      "metadata": {
        "id": "dGKt0kMjmi0G"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_for_check = next(iter(train_iterator))\n",
        "print(sample_for_check)\n",
        "print(sample_for_check.text)\n",
        "print(sample_for_check.label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcD79qzSm8HV",
        "outputId": "b1b0bdd5-8df8-4a21-fbfb-c8d140bda0e8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[torchtext.data.batch.Batch of size 30]\n",
            "\t[.text]:[torch.LongTensor of size 30x500]\n",
            "\t[.label]:[torch.FloatTensor of size 30]\n",
            "tensor([[   1,    1,    1,  ..., 1164,    6,  383],\n",
            "        [   1,    1,    1,  ...,   15,    2, 4762],\n",
            "        [   1,    1,    1,  ...,  103,   11,  120],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    4, 1609,  371],\n",
            "        [ 463,  109,  176,  ...,    9,    7,  469],\n",
            "        [   1,    1,    1,  ..., 2414, 1468, 2344]])\n",
            "tensor([0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
            "        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentenceClassification(nn.Module):\n",
        "  def __init__(self, **model_config):\n",
        "    super(SentenceClassification, self).__init__()\n",
        "\n",
        "    if model_config['emb_type'] == 'glove' or 'fasttext':\n",
        "      self.emb = nn.Embedding(model_config['vocab_size'],\n",
        "                              model_config['emb_dim'],\n",
        "                              _weight = TEXT.vocab.vectors)\n",
        "    else:\n",
        "      self.emb = nn.Embedding(model_config['vocab_size'],\n",
        "                              model_config['emb_dim'])\n",
        "\n",
        "    self.bidirectional = model_config['bidirectional']\n",
        "    self.num_direction = 2 if model_config['bidirectional'] else 1\n",
        "    self.model_type = model_config['model_type']\n",
        "\n",
        "    self.RNN = nn.RNN(input_size = model_config['emb_dim'],\n",
        "                      hidden_size = model_config['hidden_dim'],\n",
        "                      dropout=model_config['dropout'],\n",
        "                      bidirectional = model_config['bidirectional'],\n",
        "                      batch_first = model_config['batch_first'])\n",
        "\n",
        "    self.LSTM = nn.LSTM(input_size = model_config['emb_dim'],\n",
        "                      hidden_size = model_config['hidden_dim'],\n",
        "                      dropout=model_config['dropout'],\n",
        "                      bidirectional = model_config['bidirectional'],\n",
        "                      batch_first = model_config['batch_first'])\n",
        "\n",
        "    self.GRU = nn.GRU(input_size = model_config['emb_dim'],\n",
        "                      hidden_size = model_config['hidden_dim'],\n",
        "                      dropout=model_config['dropout'],\n",
        "                      bidirectional = model_config['bidirectional'],\n",
        "                      batch_first = model_config['batch_first'])\n",
        "\n",
        "    self.fc = nn.Linear(model_config['hidden_dim'] * self.num_direction,\n",
        "                        model_config['output_dim'])\n",
        "    self.drop = nn.Dropout(model_config['dropout'])\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    emb = self.emb(x)\n",
        "\n",
        "    if self.model_type == 'RNN':\n",
        "      output, hidden = self.RNN(emb)\n",
        "    elif self.model_type == 'LSTM':\n",
        "      output, (hidden, cell) = self.LSTM(emb)\n",
        "    elif self.model_type == 'GRU':\n",
        "      output, hidden = self.GRU(emb)\n",
        "    else :\n",
        "      raise NameError('Select model_type in [RNN, LSTM, GRU]')\n",
        "\n",
        "    last_output = output[:,-1,:]\n",
        "\n",
        "    return self.fc(self.drop(last_output))"
      ],
      "metadata": {
        "id": "m3Zossfqoo5G"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
        "\n",
        "def binary_accuracy(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float()\n",
        "    acc = correct.sum()/len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "0V4YKm2bu9yf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, loss_fn, idx_epoch, **model_params):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "    batch_size = model_params['batch_size']\n",
        "\n",
        "    for idx, batch in enumerate(iterator):\n",
        "\n",
        "        # Initializing\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward\n",
        "        predictions = model(batch.text).squeeze()\n",
        "        loss = loss_fn(predictions, batch.label)\n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "        sys.stdout.write(\n",
        "                    \"\\r\" + f\"[Train] Epoch : {idx_epoch:^3}\"\\\n",
        "                    f\"[{(idx + 1) * batch_size} / {len(iterator) * batch_size} ({100. * (idx + 1) / len(iterator) :.4}%)]\"\\\n",
        "                    f\"  Loss: {loss.item():.4}\"\\\n",
        "                    f\"  Acc : {acc.item():.4}\"\\\n",
        "                    )\n",
        "\n",
        "        # Backward\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update Epoch Performance\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss/len(iterator) , epoch_acc/len(iterator)"
      ],
      "metadata": {
        "id": "6f0dYkBTuPAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, loss_fn):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # evaluation mode\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            loss = loss_fn(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "TrpKQPNovKbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_config.update(dict(batch_first = True,\n",
        "                         model_type = 'RNN',\n",
        "                         bidirectional = True,\n",
        "                         hidden_dim = 128,\n",
        "                         output_dim = 1,\n",
        "                         dropout = 0))\n",
        "model_config['model_type'] = 'RNN'\n",
        "model = SentenceClassification(**model_config).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
        "N_EPOCH = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "model_name = f\"{'bi-' if model_config['bidirectional'] else ''}{model_config['model_type']}_{model_config['emb_type']}\"\n",
        "\n",
        "print('---------------------------------')\n",
        "print(f'Model name : {model_name}')\n",
        "print('---------------------------------')\n",
        "\n",
        "for epoch in range(N_EPOCH):\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, loss_fn, epoch, **model_config)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_fn)\n",
        "    print('')\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), f'./{model_name}.pt')\n",
        "        print(f'\\t Saved at {epoch}-epoch')\n",
        "\n",
        "    print(f'\\t Epoch : {epoch} | Train Loss : {train_loss:.4} | Train Acc : {train_acc:.4}')\n",
        "    print(f'\\t Epoch : {epoch} | Valid Loss : {valid_loss:.4} | Valid Acc : {valid_acc:.4}')"
      ],
      "metadata": {
        "id": "_Qx3ys73xTJp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}